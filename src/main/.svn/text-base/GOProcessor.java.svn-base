/*
 * To change this template, choose Tools | Templates
 * and open the template in the editor.
 */

package main;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.InputStreamReader;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Comparator;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;
import java.util.StringTokenizer;
import java.util.TreeSet;
import org.geneontology.oboedit.dataadapter.DefaultOBOParser;
import org.geneontology.oboedit.dataadapter.OBOParseEngine;
import org.geneontology.oboedit.dataadapter.OBOParseException;
import org.geneontology.oboedit.datamodel.IdentifiedObject;
import org.geneontology.oboedit.datamodel.Link;
import org.geneontology.oboedit.datamodel.OBOClass;
import org.geneontology.oboedit.datamodel.OBOSession;
import org.geneontology.oboedit.datamodel.impl.OBORestrictionImpl;
import kmean.DataVector;
import kmean.DataCluster;
import kmean.KMeanClusterer;
import util.StopWatch;

/**
 * 2009/11/04 - Knack   - Modify GOProcessor class to parse new ontology_file.txt to retrieve parents of each GO Term
 * @author Knacky
 */


public class GOProcessor {
    static OBOSession session;

    static Set<GOTerm> setOfGO = new HashSet<GOTerm>();

    Map<Object,Map<GOTerm,Double>> clusterNumMemMap = new HashMap<Object,Map<GOTerm,Double>>();

    /**
     * Use clusterScoreMap for storing information for both bioNodes and cluster
     */
    Map<Object,Map<GOTerm,Double>> clusterScoreMap = new HashMap<Object,Map<GOTerm,Double>>();
    
    public static Map<NameSpace,Double> weightMap = new HashMap();
//    public double ccWeight = 1;
//    public double mfWeight = 1;
//    public double bpWeight = 1;
       
    static Map<String,GOTerm> goTermsMap = new HashMap<String,GOTerm>();
    Map <Object,DataVector> nodesGOVectorMap = new HashMap<Object, DataVector>();

    public static void setWeightMap(Map map){
        weightMap = map;
    }
    public static Map<NameSpace,Double> getWeightMap(){
        return weightMap;
    }


    /** 
     * Load GO Terms from text file
     * Text file stores GO ids, names, depths, etc.
     * @throws java.io.FileNotFoundException
     * @throws java.io.IOException
     */
    public static void loadGOTermsMap() throws FileNotFoundException, IOException{
        BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(new File("src/datasets/GO_with_depth.txt"))));
        String st = "";
        StringTokenizer stn = null;
        int count = 0;
        while ((st = br.readLine()) != null){
            stn = new StringTokenizer(st,"\t");
            String id = stn.nextToken();
            String name = stn.nextToken();
            String namespace = stn.nextToken();
//            System.out.println(id+ " "+name+" "+namespace);
            int depth = Integer.parseInt(stn.nextToken());
            GOTerm term = new GOTerm(id,depth);
//            System.out.println(NameSpace.valueOf(namespace));
            term.setName(name); term.setNamespace(NameSpace.valueOf(namespace));
            goTermsMap.put(id, term);
            count ++;
        }
        System.out.println("count "+count);
        
    }

    /**
     * Load GO Terms and their information from ontology text file
     * Text file stores ontology ids, names, categories (namespaces), weights (depths), and parents.
     * @throws java.io.FileNotFoundException
     * @throws java.io.IOException
     */
    public static void loadOntologyFile() throws FileNotFoundException, IOException{
        BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(new File("src/datasets/ontology_file.txt"))));
        String st = "";
        StringTokenizer stn = null;
        int count = 0;
        while ((st = br.readLine()) != null){
            stn = new StringTokenizer(st,"\t");
            String id = stn.nextToken();
            String name = stn.nextToken();
            /* displayName is not used anywhere in the system. */
            String displayName = stn.nextToken();
            String namespace = stn.nextToken();
//            System.out.println(id+ " "+name+" "+namespace);
            int depth = Integer.parseInt(stn.nextToken());
            GOTerm term = new GOTerm(id,depth);
//            System.out.println(NameSpace.valueOf(namespace));
            term.setName(name); term.setNamespace(NameSpace.getNameSpace(namespace));
            if (stn.hasMoreTokens()) {
                String parentList = stn.nextToken();
                StringTokenizer stk = new StringTokenizer(parentList, "|");
                while (stk.hasMoreTokens()) {
                    term.addParent(stk.nextToken().trim());
                }
                
            }
            goTermsMap.put(id, term);
            count ++;
        }
        System.out.println("count "+count);

    }

    Map<GOTerm,Set<String>> ancestorsMap = new HashMap<GOTerm,Set<String>>();
    public Set<String> getAllAncestors(GOTerm goterm){
        Set<String> ancestors = new HashSet<String>();

        /* Collect only parents (parents) that have is_a or part_of relationships
         * with the the oboclass are valid.
         */
//        for (String isaParent : goterm.getIsaSet()){
//            ancestors.add(isaParent);
//        }
//        for (Relationship relParent : goterm.getRelationshipSet()){
//            if (relParent.getType().equalsIgnoreCase("part_of")){
//                ancestors.add(relParent.getTarget());
//            }
//        }
        ancestors.addAll(goterm.getParents());
        Set<String> tempAncestors = new HashSet<String>(ancestors);
        for (String term : tempAncestors){
            GOTerm tempTerm = goTermsMap.get(term);
            Set<String> requiredAncestors = ancestorsMap.get(tempTerm);
            if (requiredAncestors == null){
                requiredAncestors = getAllAncestors(tempTerm);
                ancestorsMap.put(tempTerm, requiredAncestors);
            }
            ancestors.addAll(requiredAncestors);
        }
        return ancestors;
    }
    /**
     * Create mapping of nodes into GO term-score map
     * GO term-score map is mapping from GO terms into score of that terms
     * @param cSet
     * @return map of node into GO term-score map
     */
    public Map<Object,Map<GOTerm,Double>> populateGOTerms(Set cSet){
        clusterScoreMap =
                new HashMap<Object, Map<GOTerm, Double>>();
     
        Map<GOTerm, Double> numMembersMap = new HashMap<GOTerm, Double>();
        Map<GOTerm, Double> scoreMap = new HashMap<GOTerm, Double>();
        setOfGO.add(new GOTerm("GO:0008150", 1));
        setOfGO.add(new GOTerm("GO:0005575", 1));
        setOfGO.add(new GOTerm("GO:0003674", 1));
        /* Assume that cSet purely contains either bioObject or set. */
        for (Object obj : cSet) {
            
            boolean isBioObjectSet = false;
            Set cluster = null;
            BioObject bioNode = null;
//            if (isBioObjectSet) {
            if (obj instanceof BioObject) {
                bioNode = (BioObject) obj;
                isBioObjectSet = true;
            } else if (obj instanceof Set){
                cluster = (Set) obj;
            } else
                System.out.println("Error neither BioObj nor Set");

            numMembersMap.clear();
            scoreMap.clear();

            /* if cSet is a set of bioObject */
            if (isBioObjectSet) {

                Set<String> goidset = new HashSet<String>();
                /* add all ancestors of GO terms specified in the GoIdlist to expand annotating term set
                 */
//                for (String goid : bioNode.getGoIdList()) {
//                    goidset.add(goid);
//                    Set<String> ancestors = ancestorsMap.get(goid);
//                    if (ancestors == null) {
//                        ancestors = getAllAncestors(goTermsMap.get(goid));
//                        ancestorsMap.put(goTermsMap.get(goid), ancestors);
//                    }
//                    goidset.addAll(ancestors);
//                }
                goidset.addAll(bioNode.getGoIdList());
                for (String id : goidset) {

                    GOTerm term = GOTerm.findGO(scoreMap.keySet(), id);
                    
                    if (term == null) {

                        term = new GOTerm(id, goTermsMap.get(id).getDepth());
                        term.setNamespace(goTermsMap.get(id).getNamespace());
                        /* for bioObject, for each GO term, the score is the depth of that term */
                        scoreMap.put(term, (double) 1 * term.getDepth()*weightMap.get(term.getNamespace()));
                    }
                /* There shouldn't be duplicate of a specific GO term in one BioObject */
                }

            } else {
            /* if cSet is a set of cluster */
                for (Object node : cluster) {
                    bioNode = (BioObject) node;
//                System.out.println("Node "+bioNode);
                    Set<String> goidset = new HashSet<String>();
                    /* add all ancestors of GO terms specified in the GoIdlist to expand annotating term set
                     */
//                    for (String goid : bioNode.getGoIdList()) {
//                        goidset.add(goid);
//                        Set<String> ancestors = ancestorsMap.get(goid);
//                        if (ancestors == null) {
//                            ancestors = getAllAncestors(goTermsMap.get(goid));
//                            ancestorsMap.put(goTermsMap.get(goid), ancestors);
//                        }
//                        goidset.addAll(ancestors);
//                    }
                    goidset.addAll(bioNode.getGoIdList());
                    for (String id : goidset) {

                        GOTerm term = goTermsMap.get(id);
                        if (!scoreMap.containsKey(goTermsMap.get(id))) {
                            scoreMap.put(term, (double) 1 / cluster.size() * term.getDepth()*weightMap.get(term.getNamespace()));
                        } else {
                            scoreMap.put(term, (Double) scoreMap.get(term) + ((double) 1 / cluster.size() * term.getDepth())*weightMap.get(term.getNamespace()));
                        }
                    }

                }

            }
            double normalizedFactor = 0.0;
            for (Entry<GOTerm, Double> entry : scoreMap.entrySet()) {
                normalizedFactor += entry.getValue() * entry.getValue();
            }
            normalizedFactor = Math.sqrt(normalizedFactor);
            for (GOTerm key : scoreMap.keySet()) {
                scoreMap.put(key, scoreMap.get(key) / normalizedFactor);
            }

//            System.out.println("Stat for cluster");
//            System.out.println("Size: " + cluster.size());
            
            Map<GOTerm, Double> map = new HashMap<GOTerm, Double>(numMembersMap);
            clusterNumMemMap.put(cluster, map);
//            System.out.println("numberMap size: "+numMembersMap.size());
            map.clear();
            map = new HashMap<GOTerm, Double>(scoreMap);
                        
            if (isBioObjectSet){
//              clusterScoreMap.remove(cluster);
                clusterScoreMap.put(bioNode, map);
            } else {
                clusterScoreMap.put(cluster, map);
            } 

        }

        System.out.println("clusterScoreMap size: " + clusterScoreMap.size());

        return clusterScoreMap;
    }
    
    /**
     * Assume that populateGOTerms is already called.
     * Just put clusterScoreMap to mapping of cluster into datavector
     * Do not clear nodesGOVectorMap for sake of reusability with nodes of many levels
     * @param cSet
     * @return nodesGOVectorMap
     */
    public Map<Object, DataVector> getNodesGOVectorMapBeforeCluster(Set cSet){

        for (Object obj : cSet){
            if (clusterScoreMap.get(obj)==null)
                System.out.println("Vertex : "+obj+" has no clusterScoreMap");
            DataVector vec = new DataVector(clusterScoreMap.get(obj));
            vec.nodeRef = obj;
            nodesGOVectorMap.put(obj, vec);
        }
        return nodesGOVectorMap;
    }
    
    /**
     * For cSet of BioObject only
     * Assume that for BioObject set, cSet is the same as comNodeCSet
     * @param cSet
     * @param numCluster
     * @return
     */
    public DataCluster[] preCluster(Set cSet,int numCluster){
        KMeanClusterer kCluster = new KMeanClusterer(numCluster);
        
//        Set[] arrCluster = cSet.toArray(new Set[1]);
        Object[] arrCluster = cSet.toArray(new Object[1]);
                
        for (int i = 0; i < arrCluster.length; i++){

            Map<GOTerm,Double> scoreMap;
            Map<String,Double> stringScoreMap;
            Map map = clusterScoreMap.get(arrCluster[i]);
            if (map == null)
                System.out.println("NULL++++++++");
            scoreMap = new HashMap<GOTerm, Double>(map);
            stringScoreMap = new HashMap<String, Double>();

            int ind = 0;
            for (Entry<GOTerm, Double> entry : scoreMap.entrySet()){

                stringScoreMap.put(entry.getKey().getId(), entry.getValue());
                ind++;
            }

            DataVector vec = new DataVector(map);
            
            vec.nodeRef = arrCluster[i];
            /* vec.comNodeClusterRef has no special meaning in this case */
            vec.comNodeClusterRef = arrCluster[i];
            
            kCluster.dataVectorList.add(vec);
                
        }
        kCluster.assignKPoint();
        StopWatch sw = new StopWatch();
        sw.start();
        kCluster.cluster();
        sw.stop();
        System.out.println("Time used for clustering: "+sw);

        return kCluster.getClusterList();
        
    }

    /**
     * For cSet of clusters
     * @param comNodeClustToFlatClust
     * @param comNodeCSet
     * @param cSet
     * @param numCluster
     * @return
     */
    public DataCluster[] preCluster(Map<Set, Set> comNodeClustToFlatClust,Set<Set> comNodeCSet, Set<Set> cSet,int numCluster){
        KMeanClusterer kCluster = new KMeanClusterer(numCluster);

        Set[] arrCluster = comNodeCSet.toArray(new Set[1]);
                
        for (int i = 0; i < arrCluster.length; i++){

            Map<GOTerm,Double> scoreMap;
            Map<String,Double> stringScoreMap;
            Map<GOTerm,Double> mapOfComNodeClustI = clusterScoreMap.get(comNodeClustToFlatClust.get(arrCluster[i]));
            if (mapOfComNodeClustI == null)
                System.out.println("Error! cannot find entry for "+comNodeClustToFlatClust.get(arrCluster[i]));
            scoreMap = new HashMap<GOTerm, Double>(mapOfComNodeClustI);
            stringScoreMap = new HashMap<String, Double>();

            int ind = 0;
            for (Entry<GOTerm, Double> entry : scoreMap.entrySet()){
//                System.out.println(entry.getKey());
                stringScoreMap.put(entry.getKey().getId(), entry.getValue());
                ind++;
            }

            DataVector vec = new DataVector(mapOfComNodeClustI);
            
            vec.nodeRef = comNodeClustToFlatClust.get(arrCluster[i]);
            vec.comNodeClusterRef = arrCluster[i];
            
            kCluster.dataVectorList.add(vec);
                
        }

        StopWatch sw = new StopWatch();
        sw.start();
        kCluster.assignKPoint();
        sw.stop();
        System.out.println("Time used for assigning K points: "+sw);

        sw.start();
        kCluster.cluster();
        sw.stop();
        System.out.println("Time used for clustering: "+sw);

        return kCluster.getClusterList();
        
    }
    
    /**
     * Copied and modified version of getSession method described in gene ontology website
     * This is used for parse obo flat file (text file describing GO terms)
     * @param path
     * @return
     * @throws java.io.IOException
     * @throws org.geneontology.oboedit.dataadapter.OBOParseException
     */
    public static OBOSession getSession(String path) throws IOException, OBOParseException {

        DefaultOBOParser parser = new DefaultOBOParser();
        OBOParseEngine engine = new OBOParseEngine(parser);
        // GOBOParseEngine can parse several files at once
        // and create one munged-together ontology,
        // so we need to provide a Collection to the setPaths() method
        Collection paths = new LinkedList();
        paths.add(path);
        engine.setPaths(paths);
        engine.parse();
        session = parser.getSession();
        return session;
    }

    /**
     * Previously used to test this class.
     * @param args
     * @throws java.io.FileNotFoundException
     * @throws java.io.IOException
     */
    public static void main(String[] args) throws FileNotFoundException, IOException {
        loadOntologyFile();
//        try {
//            loadGOTermsMap();
//            
//        } catch (FileNotFoundException ex) {
//            Logger.getLogger(GOProcessor.class.getName()).log(Level.SEVERE, null, ex);
//        } catch (IOException ex) {
//            Logger.getLogger(GOProcessor.class.getName()).log(Level.SEVERE, null, ex);
//        }
//        Set s1 = new HashSet();Set s2 = new HashSet();Set s3 = new HashSet();
//        s2.add(1); s2.add(2); s3.add(3); s3.add(4);
//        s1.addAll(s2); s1.addAll(s3);
//        Set ss1 = new HashSet(); Set ss2 = new HashSet();
//        ss1.addAll(s1);
//        System.out.println("ss1" +ss1);
//        s1.clear();
//        s1.add(s2); s1.add(s3);
//        ss1.clear();
//        ss1.add(s1);
//        System.out.println("ss1" +ss1);
        
    }
}
